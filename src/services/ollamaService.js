/**
 * Ollama AI æœå‹™æ¨¡çµ„
 * è·¯å¾‘: sailo_backend/src/services/ollamaService.js
 *
 * åŠŸèƒ½èªªæ˜:
 * - èˆ‡ Ollama API äº’å‹•
 * - ç®¡ç†å°è©±ä¸Šä¸‹æ–‡
 * - è™•ç† AI å›æ‡‰
 * - éŒ¯èª¤è™•ç†èˆ‡é‡è©¦æ©Ÿåˆ¶
 *
 * æ ¸å¿ƒåŠŸèƒ½:
 * 1. ç”Ÿæˆ AI å›æ‡‰
 * 2. å°è©±ä¸Šä¸‹æ–‡ç®¡ç†
 * 3. é—œéµå­—åµæ¸¬ (è½‰æ¥äººå·¥)
 * 4. Token ä½¿ç”¨çµ±è¨ˆ
 *
 * ä½¿ç”¨æ–¹å¼:
 * import { generateAIResponse, analyzeTransferIntent } from '@/services/ollamaService'
 */

import { OLLAMA_CONFIG } from '../config/ollama.js'
import { executeUserQuery, suggestQueryType } from './databaseQueryService.js'

/**
 * å‘¼å« Ollama Chat API
 *
 * @param {Array} messages - å°è©±è¨Šæ¯é™£åˆ— [{role: 'user'|'assistant'|'system', content: '...'}]
 * @param {Object} options - é¸é … {temperature, stream, etc.}
 * @returns {Promise<{response: string, tokens: number}>}
 */
export async function callOllamaChat(messages, options = {}) {
  try {
    const requestBody = {
      model: OLLAMA_CONFIG.MODEL,
      messages,
      stream: false, // ä¸ä½¿ç”¨ä¸²æµæ¨¡å¼
      options: {
        temperature:
          options.temperature || OLLAMA_CONFIG.PARAMETERS.temperature,
        top_p: options.top_p || OLLAMA_CONFIG.PARAMETERS.top_p,
        top_k: options.top_k || OLLAMA_CONFIG.PARAMETERS.top_k,
        num_predict:
          options.num_predict || OLLAMA_CONFIG.PARAMETERS.num_predict,
        repeat_penalty:
          options.repeat_penalty || OLLAMA_CONFIG.PARAMETERS.repeat_penalty,
      },
    }

    console.log('ğŸ¤– å‘¼å« Ollama API:', {
      model: requestBody.model,
      messagesCount: messages.length,
    })

    const response = await fetch(
      `${OLLAMA_CONFIG.BASE_URL}${OLLAMA_CONFIG.ENDPOINTS.CHAT}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(requestBody),
        signal: AbortSignal.timeout(OLLAMA_CONFIG.TIMEOUT.CHAT),
      }
    )

    if (!response.ok) {
      throw new Error(`Ollama API éŒ¯èª¤: HTTP ${response.status}`)
    }

    const data = await response.json()

    // æå–å›æ‡‰å…§å®¹
    const aiResponse = data.message?.content || ''
    const tokensUsed = (data.eval_count || 0) + (data.prompt_eval_count || 0)

    console.log('âœ… Ollama å›æ‡‰æˆåŠŸ:', {
      responseLength: aiResponse.length,
      tokensUsed,
    })

    return {
      response: aiResponse,
      tokens: tokensUsed,
    }
  } catch (error) {
    console.error(' Ollama API å‘¼å«å¤±æ•—:', error)

    // éŒ¯èª¤é¡å‹åˆ¤æ–·
    if (error.name === 'AbortError') {
      throw new Error('AI å›æ‡‰è¶…æ™‚,è«‹ç¨å¾Œå†è©¦')
    }

    throw new Error(`AI æœå‹™ç•°å¸¸: ${error.message}`)
  }
}

/**
 * ç”Ÿæˆ AI å®¢æœå›æ‡‰
 *
 * ğŸ†• v4.0.0: æ–°å¢è³‡æ–™åº«æŸ¥è©¢åŠŸèƒ½
 * - è‡ªå‹•åµæ¸¬ä½¿ç”¨è€…æ˜¯å¦éœ€è¦æŸ¥è©¢è³‡æ–™åº«
 * - åŸ·è¡Œå®‰å…¨çš„è³‡æ–™åº«æŸ¥è©¢
 * - å°‡æŸ¥è©¢çµæœæ•´åˆåˆ° AI å›æ‡‰ä¸­
 *
 * @param {string} userMessage - ä½¿ç”¨è€…è¨Šæ¯
 * @param {Array} conversationHistory - å°è©±æ­·å² [{role, content}, ...]
 * @param {number} userId - ä½¿ç”¨è€… IDï¼ˆç”¨æ–¼è³‡æ–™åº«æŸ¥è©¢ï¼‰
 * @returns {Promise<{response: string, tokens: number, shouldTransfer: boolean, queryExecuted: boolean}>}
 */
export async function generateAIResponse(
  userMessage,
  conversationHistory = [],
  userId = null
) {
  try {
    let queryResult = null
    let queryExecuted = false

    // ğŸ†• æ­¥é©Ÿ 1: æª¢æŸ¥æ˜¯å¦éœ€è¦æŸ¥è©¢è³‡æ–™åº«
    if (userId) {
      const suggestedQuery = suggestQueryType(userMessage)

      if (suggestedQuery) {
        console.log('ğŸ” åµæ¸¬åˆ°è³‡æ–™åº«æŸ¥è©¢éœ€æ±‚:', suggestedQuery)

        try {
          queryResult = await executeUserQuery(suggestedQuery, userId)
          queryExecuted = true
          console.log('âœ… è³‡æ–™åº«æŸ¥è©¢æˆåŠŸ')
        } catch (error) {
          console.error(' è³‡æ–™åº«æŸ¥è©¢å¤±æ•—:', error)
          queryResult = 'æŠ±æ­‰ï¼ŒæŸ¥è©¢è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚'
        }
      }
    }

    // æ­¥é©Ÿ 2: å»ºæ§‹å®Œæ•´å°è©±ä¸Šä¸‹æ–‡
    const messages = [
      // ç³»çµ±æç¤ºè©
      {
        role: 'system',
        content: queryResult
          ? `${OLLAMA_CONFIG.SYSTEM_PROMPT}\n\nã€é‡è¦ã€‘ä»¥ä¸‹æ˜¯å¾è³‡æ–™åº«æŸ¥è©¢åˆ°çš„ä½¿ç”¨è€…è³‡æ–™ï¼Œè«‹æ ¹æ“šé€™äº›è³‡æ–™å›ç­”ä½¿ç”¨è€…çš„å•é¡Œï¼š\n${queryResult}`
          : OLLAMA_CONFIG.SYSTEM_PROMPT,
      },
      // æ­·å²å°è©± (æœ€å¤šä¿ç•™ 10 è¼ª)
      ...conversationHistory.slice(-20),
      // ç•¶å‰ä½¿ç”¨è€…è¨Šæ¯
      {
        role: 'user',
        content: userMessage,
      },
    ]

    // æ­¥é©Ÿ 3: å‘¼å« Ollama API
    const { response, tokens } = await callOllamaChat(messages)

    // æ­¥é©Ÿ 4: åˆ†ææ˜¯å¦éœ€è¦è½‰æ¥äººå·¥
    const shouldTransfer = analyzeTransferIntent(userMessage, response)

    return {
      response,
      tokens,
      shouldTransfer,
      queryExecuted, // ğŸ†• è¿”å›æ˜¯å¦åŸ·è¡Œäº†è³‡æ–™åº«æŸ¥è©¢
    }
  } catch (error) {
    console.error(' ç”Ÿæˆ AI å›æ‡‰å¤±æ•—:', error)
    throw error
  }
}

/**
 * åˆ†ææ˜¯å¦éœ€è¦è½‰æ¥äººå·¥å®¢æœ
 *
 * ğŸ†• v3.2.0 ä¿®æ”¹:
 * - åªæª¢æŸ¥ç”¨æˆ¶è¨Šæ¯ï¼Œä¸æª¢æŸ¥ AI å›æ‡‰
 * - é¿å… AI å›æ‡‰ä¸­çš„ã€Œè½‰äººå·¥ã€é—œéµå­—èª¤è§¸ç™¼è½‰æ¥
 *
 * è§¸ç™¼æ¢ä»¶:
 * 1. ä½¿ç”¨è€…æ˜ç¢ºè¦æ±‚çœŸäººå®¢æœ
 * 2. æ¶‰åŠæ•æ„Ÿæ“ä½œ (é€€æ¬¾ã€ä¿®æ”¹è³‡æ–™ç­‰)
 *
 * @param {string} userMessage - ä½¿ç”¨è€…è¨Šæ¯
 * @param {string} aiResponse - AI å›æ‡‰ (æš«ä¸ä½¿ç”¨)
 * @returns {boolean}
 */
export function analyzeTransferIntent(userMessage, aiResponse) {
  // ä½¿ç”¨è€…é—œéµå­—
  const userKeywords = [
    'çœŸäººå®¢æœ',
    'äººå·¥å®¢æœ',
    'è½‰æ¥å®¢æœ',
    'æ‰¾å®¢æœ',
    'çœŸäºº',
    'äººå·¥',
    'å®¢æœäººå“¡',
    'human',
    'agent',
    'ä¸æ»¿æ„',
    'æŠ•è¨´',
    'æŠ±æ€¨',
  ]

  // æ•æ„Ÿæ“ä½œé—œéµå­—
  const sensitiveKeywords = ['é€€æ¬¾', 'é€€éŒ¢', 'é€€è²»', 'ä¿¡ç”¨å¡']

  // ğŸ†• v3.2.0: åªæª¢æŸ¥ä½¿ç”¨è€…è¨Šæ¯ï¼Œä¸æª¢æŸ¥ AI å›æ‡‰
  const userWantsHuman = userKeywords.some((keyword) =>
    userMessage.toLowerCase().includes(keyword.toLowerCase())
  )

  // æª¢æŸ¥æ•æ„Ÿæ“ä½œ
  const isSensitive = sensitiveKeywords.some((keyword) =>
    userMessage.includes(keyword)
  )

  //  ç§»é™¤ AI å›æ‡‰æª¢æ¸¬ï¼Œé¿å…èª¤è§¸ç™¼
  // const aiSuggestsTransfer = aiTransferKeywords.some((keyword) =>
  //   aiResponse.includes(keyword)
  // )

  return userWantsHuman || isSensitive
}

/**
 * ç”Ÿæˆæ­¡è¿è¨Šæ¯
 *
 * @returns {string}
 */
export function getWelcomeMessage() {
  return `æ‚¨å¥½ï¼æˆ‘æ˜¯ SailoTravel çš„ AI å®¢æœåŠ©æ‰‹

æˆ‘å¯ä»¥å”åŠ©æ‚¨:
â€¢ æŸ¥è©¢è¨‚å–®ç‹€æ…‹
â€¢ äº†è§£é€€æ›è²¨æ”¿ç­–
â€¢ è§£ç­”ä»˜æ¬¾ç›¸é—œå•é¡Œ
â€¢ æ¨è–¦æ—…éŠæ™¯é»èˆ‡è¡Œç¨‹

å¦‚æœ‰ä»»ä½•å•é¡Œ,æ­¡è¿éš¨æ™‚è©¢å•ï¼
è‹¥éœ€è¦æ›´è©³ç´°çš„å”åŠ©,æˆ‘ä¹Ÿå¯ä»¥ç‚ºæ‚¨è½‰æ¥çœŸäººå®¢æœã€‚`
}

/**
 * ç”Ÿæˆè½‰æ¥ç¢ºèªè¨Šæ¯
 *
 * @returns {string}
 */
export function getTransferConfirmMessage() {
  return `æˆ‘å°‡ç‚ºæ‚¨è½‰æ¥çœŸäººå®¢æœ,è«‹ç¨å€™...

æ‚¨çš„å°è©±è¨˜éŒ„å°‡æœƒä¸€ä½µè½‰äº¤çµ¦å®¢æœäººå“¡,ä»¥ä¾¿æä¾›æ›´å¥½çš„æœå‹™ã€‚`
}

/**
 * ç”ŸæˆéŒ¯èª¤è¨Šæ¯
 *
 * @param {Error} error - éŒ¯èª¤ç‰©ä»¶
 * @returns {string}
 */
export function getErrorMessage(error) {
  if (error.message.includes('è¶…æ™‚')) {
    return 'æŠ±æ­‰,AI å›æ‡‰è¶…æ™‚äº†ã€‚æ‚¨å¯ä»¥:\n1. é‡æ–°ç™¼é€æ‚¨çš„å•é¡Œ\n2. è½‰æ¥çœŸäººå®¢æœç²å¾—å”åŠ©'
  }

  if (error.message.includes('é€£ç·š')) {
    return 'æŠ±æ­‰,AI æœå‹™æš«æ™‚ç„¡æ³•ä½¿ç”¨ã€‚è«‹è½‰æ¥çœŸäººå®¢æœ,æˆ‘å€‘å°‡ç‚ºæ‚¨æä¾›å”åŠ©ã€‚'
  }

  return 'æŠ±æ­‰,ç›®å‰ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ã€‚å»ºè­°æ‚¨è½‰æ¥çœŸäººå®¢æœä»¥ç²å¾—æ›´å¥½çš„å”åŠ©ã€‚'
}

export default {
  callOllamaChat,
  generateAIResponse,
  analyzeTransferIntent,
  getWelcomeMessage,
  getTransferConfirmMessage,
  getErrorMessage,
}
